{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f3d5fe-08bc-4289-8253-5ebaf08ed15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This extracts captions from n frames of the video, with n being the number of files in the frames directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a01f0c8c-25dd-484e-af74-d230e767d21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.19045.2965]\n",
      "(c) Microsoft Corporation. All rights reserved.\n",
      "\n",
      "C:\\dev\\valberts\\Crime-Recognition-from-Context-Representation>%windir%\\System32\\cmd.exe \"/K\" C:\\Users\\alber\\anaconda3-researchproject\\Scripts\\activate.bat\n",
      "\n",
      "(base) C:\\dev\\valberts\\Crime-Recognition-from-Context-Representation>conda info --envs\n",
      "# conda environments:\n",
      "#\n",
      "base                  *  C:\\Users\\alber\\anaconda3-researchproject\n",
      "crime-recognition        C:\\Users\\alber\\anaconda3-researchproject\\envs\\crime-recognition\n",
      "pizza                    C:\\Users\\alber\\anaconda3-researchproject\\envs\\pizza\n",
      "vincent                  C:\\Users\\alber\\anaconda3-researchproject\\envs\\vincent\n",
      "\n",
      "\n",
      "(base) C:\\dev\\valberts\\Crime-Recognition-from-Context-Representation>conda activate pizza\n",
      "\n",
      "(pizza) C:\\dev\\valberts\\Crime-Recognition-from-Context-Representation>cd ExpansionNet_v2-master\n",
      "\n",
      "(pizza) C:\\dev\\valberts\\Crime-Recognition-from-Context-Representation\\ExpansionNet_v2-master>python demo_multi.py --load_path github_ignore_material/rf_model-003.pth \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alber\\anaconda3-researchproject\\envs\\pizza\\lib\\site-packages\\torch\\functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary loaded ...\n",
      "Model loaded ...\n",
      "Generating captions ...\n",
      "\n",
      "Closed.\n",
      "\n",
      "(pizza) C:\\dev\\valberts\\Crime-Recognition-from-Context-Representation\\ExpansionNet_v2-master>\n",
      "C:\\dev\\valberts\\Crime-Recognition-from-Context-Representation>"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "%windir%\\System32\\cmd.exe \"/K\" C:\\Users\\alber\\anaconda3-researchproject\\Scripts\\activate.bat\n",
    "conda info --envs\n",
    "conda activate pizza\n",
    "cd ExpansionNet_v2-master\n",
    "python demo_multi.py --load_path github_ignore_material/rf_model-003.pth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b38036-dbd1-4e2c-9f8c-eab569e19078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting frames from videos\n",
    "\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "\n",
    "home_path = \"C:/dev/valberts/Crime-Recognition-from-Context-Representation/ExpansionNet_v2-master/\"\n",
    "videos_path = \"C:/dev/valberts/Crime-Recognition-from-Context-Representation/ExpansionNet_v2-master/UCF_Videos/\"\n",
    "folders = glob.glob(f\"{videos_path}/*\")\n",
    "categories = []\n",
    "\n",
    "for f in folders:\n",
    "    categories.append(f.split(\"\\\\\")[1])\n",
    "\n",
    "os.mkdir(\"ExpansionNet_v2-master/video_frames\")\n",
    "\n",
    "for cat in categories:\n",
    "    os.mkdir(f\"ExpansionNet_v2-master/video_frames/{cat}\")\n",
    "    videos = glob.glob(f\"{path}{cat}/*\")\n",
    "    for vid in videos:\n",
    "        vid_name = ((vid.split(\"\\\\\")[1]).split(\".\")[0]).split(\"_\")[0]\n",
    "        os.mkdir(f\"ExpansionNet_v2-master/video_frames/{cat}/{vid_name}\")\n",
    "        vidcap = cv2.VideoCapture(vid)\n",
    "        total_frames = vidcap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "        desired_frames = 10\n",
    "        frames_step = total_frames//desired_frames\n",
    "        print(vid_name)\n",
    "        \n",
    "        for i in range(desired_frames):\n",
    "            vidcap.set(1, i*frames_step)\n",
    "            success,image = vidcap.read()\n",
    "            cv2.imwrite(f\"ExpansionNet_v2-master/video_frames/{cat}/{vid_name}/{cat}_{i}.png\",image)\n",
    "        vidcap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c043035f-5f76-40bd-ad46-b7c6e92035a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.19045.2965]\n",
      "(c) Microsoft Corporation. All rights reserved.\n",
      "\n",
      "C:\\dev\\valberts\\Crime-Recognition-from-Context-Representation>%windir%\\System32\\cmd.exe \"/K\" C:\\Users\\alber\\anaconda3-researchproject\\Scripts\\activate.bat\n",
      "\n",
      "(base) C:\\dev\\valberts\\Crime-Recognition-from-Context-Representation>conda info --envs\n",
      "# conda environments:\n",
      "#\n",
      "base                  *  C:\\Users\\alber\\anaconda3-researchproject\n",
      "crime-recognition        C:\\Users\\alber\\anaconda3-researchproject\\envs\\crime-recognition\n",
      "pizza                    C:\\Users\\alber\\anaconda3-researchproject\\envs\\pizza\n",
      "vincent                  C:\\Users\\alber\\anaconda3-researchproject\\envs\\vincent\n",
      "\n",
      "\n",
      "(base) C:\\dev\\valberts\\Crime-Recognition-from-Context-Representation>conda activate pizza\n",
      "\n",
      "(pizza) C:\\dev\\valberts\\Crime-Recognition-from-Context-Representation>cd high-level-context-representation\n",
      "\n",
      "(pizza) C:\\dev\\valberts\\Crime-Recognition-from-Context-Representation\\high-level-context-representation>python generate_dataset_annotations.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alber\\anaconda3-researchproject\\envs\\pizza\\lib\\site-packages\\torch\\functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading CAER-S from C:\\dev\\valberts\\Crime-Recognition-from-Context-Representation\\ExpansionNet_v2-master\\video_frames\n",
      "[INFO] Dataset will be saved to dataset/HRC_preprocessed\n",
      "Dictionary loaded ...\n",
      "Model loaded ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Split: train:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abuse001\n",
      "['Abuse_0.png', 'Abuse_1.png', 'Abuse_2.png', 'Abuse_3.png', 'Abuse_4.png', 'Abuse_5.png', 'Abuse_6.png', 'Abuse_7.png', 'Abuse_8.png', 'Abuse_9.png']\n",
      "Abuse002\n",
      "['Abuse_0.png', 'Abuse_1.png', 'Abuse_2.png', 'Abuse_3.png', 'Abuse_4.png', 'Abuse_5.png', 'Abuse_6.png', 'Abuse_7.png', 'Abuse_8.png', 'Abuse_9.png']\n",
      "Abuse003\n",
      "['Abuse_0.png', 'Abuse_1.png', 'Abuse_2.png', 'Abuse_3.png', 'Abuse_4.png', 'Abuse_5.png', 'Abuse_6.png', 'Abuse_7.png', 'Abuse_8.png', 'Abuse_9.png']\n",
      "Abuse004\n",
      "['Abuse_0.png', 'Abuse_1.png', 'Abuse_2.png', 'Abuse_3.png', 'Abuse_4.png', 'Abuse_5.png', 'Abuse_6.png', 'Abuse_7.png', 'Abuse_8.png', 'Abuse_9.png']\n",
      "Abuse005\n",
      "['Abuse_0.png', 'Abuse_1.png', 'Abuse_2.png', 'Abuse_3.png', 'Abuse_4.png', 'Abuse_5.png', 'Abuse_6.png', 'Abuse_7.png', 'Abuse_8.png', 'Abuse_9.png']\n",
      "Abuse006\n",
      "['Abuse_0.png', 'Abuse_1.png', 'Abuse_2.png', 'Abuse_3.png', 'Abuse_4.png', 'Abuse_5.png', 'Abuse_6.png', 'Abuse_7.png', 'Abuse_8.png', 'Abuse_9.png']\n",
      "Abuse007\n",
      "['Abuse_0.png', 'Abuse_1.png', 'Abuse_2.png', 'Abuse_3.png', 'Abuse_4.png', 'Abuse_5.png', 'Abuse_6.png', 'Abuse_7.png', 'Abuse_8.png', 'Abuse_9.png']\n",
      "Abuse008\n",
      "['Abuse_0.png', 'Abuse_1.png', 'Abuse_2.png', 'Abuse_3.png', 'Abuse_4.png', 'Abuse_5.png', 'Abuse_6.png', 'Abuse_7.png', 'Abuse_8.png', 'Abuse_9.png']\n",
      "Abuse009\n",
      "['Abuse_0.png', 'Abuse_1.png', 'Abuse_2.png', 'Abuse_3.png', 'Abuse_4.png', 'Abuse_5.png', 'Abuse_6.png', 'Abuse_7.png', 'Abuse_8.png', 'Abuse_9.png']\n",
      "Abuse010\n",
      "['Abuse_0.png', 'Abuse_1.png', 'Abuse_2.png', 'Abuse_3.png', 'Abuse_4.png', 'Abuse_5.png', 'Abuse_6.png', 'Abuse_7.png', 'Abuse_8.png', 'Abuse_9.png']\n",
      "Abuse011\n",
      "['Abuse_0.png', 'Abuse_1.png', 'Abuse_2.png', 'Abuse_3.png', 'Abuse_4.png', 'Abuse_5.png', 'Abuse_6.png', 'Abuse_7.png', 'Abuse_8.png', 'Abuse_9.png']\n",
      "Abuse012\n",
      "['Abuse_0.png', 'Abuse_1.png', 'Abuse_2.png', 'Abuse_3.png', 'Abuse_4.png', 'Abuse_5.png', 'Abuse_6.png', 'Abuse_7.png', 'Abuse_8.png', 'Abuse_9.png']\n",
      "Abuse013\n",
      "['Abuse_0.png', 'Abuse_1.png', 'Abuse_2.png', 'Abuse_3.png', 'Abuse_4.png', 'Abuse_5.png', 'Abuse_6.png', 'Abuse_7.png', 'Abuse_8.png', 'Abuse_9.png']\n",
      "Abuse014\n",
      "['Abuse_0.png', 'Abuse_1.png', 'Abuse_2.png', 'Abuse_3.png', 'Abuse_4.png', 'Abuse_5.png', 'Abuse_6.png', 'Abuse_7.png', 'Abuse_8.png', 'Abuse_9.png']\n",
      "Abuse015\n",
      "['Abuse_0.png', 'Abuse_1.png', 'Abuse_2.png', 'Abuse_3.png', 'Abuse_4.png', 'Abuse_5.png', 'Abuse_6.png', 'Abuse_7.png', 'Abuse_8.png', 'Abuse_9.png']\n",
      "Abuse016\n",
      "['Abuse_0.png', 'Abuse_1.png', 'Abuse_2.png', 'Abuse_3.png', 'Abuse_4.png', 'Abuse_5.png', 'Abuse_6.png', 'Abuse_7.png', 'Abuse_8.png', 'Abuse_9.png']\n",
      "Abuse017\n",
      "['Abuse_0.png', 'Abuse_1.png', 'Abuse_2.png', 'Abuse_3.png', 'Abuse_4.png', 'Abuse_5.png', 'Abuse_6.png', 'Abuse_7.png', 'Abuse_8.png', 'Abuse_9.png']\n",
      "Abuse018\n",
      "['Abuse_0.png', 'Abuse_1.png', 'Abuse_2.png', 'Abuse_3.png', 'Abuse_4.png', 'Abuse_5.png', 'Abuse_6.png', 'Abuse_7.png', 'Abuse_8.png', 'Abuse_9.png']\n",
      "Abuse019\n",
      "['Abuse_0.png', 'Abuse_1.png', 'Abuse_2.png', 'Abuse_3.png', 'Abuse_4.png', 'Abuse_5.png', 'Abuse_6.png', 'Abuse_7.png', 'Abuse_8.png', 'Abuse_9.png']\n",
      "Abuse020\n",
      "['Abuse_0.png', 'Abuse_1.png', 'Abuse_2.png', 'Abuse_3.png', 'Abuse_4.png', 'Abuse_5.png', 'Abuse_6.png', 'Abuse_7.png', 'Abuse_8.png', 'Abuse_9.png']\n",
      "Abuse021\n",
      "['Abuse_0.png', 'Abuse_1.png', 'Abuse_2.png', 'Abuse_3.png', 'Abuse_4.png', 'Abuse_5.png', 'Abuse_6.png', 'Abuse_7.png', 'Abuse_8.png', 'Abuse_9.png']\n",
      "Abuse022\n",
      "['Abuse_0.png', 'Abuse_1.png', 'Abuse_2.png', 'Abuse_3.png', 'Abuse_4.png', 'Abuse_5.png', 'Abuse_6.png', 'Abuse_7.png', 'Abuse_8.png', 'Abuse_9.png']\n",
      "Abuse023\n",
      "['Abuse_0.png', 'Abuse_1.png', 'Abuse_2.png', 'Abuse_3.png', 'Abuse_4.png', 'Abuse_5.png', 'Abuse_6.png', 'Abuse_7.png', 'Abuse_8.png', 'Abuse_9.png']\n",
      "Abuse024\n",
      "['Abuse_0.png', 'Abuse_1.png', 'Abuse_2.png', 'Abuse_3.png', 'Abuse_4.png', 'Abuse_5.png', 'Abuse_6.png', 'Abuse_7.png', 'Abuse_8.png', 'Abuse_9.png']\n",
      "Abuse025\n",
      "['Abuse_0.png', 'Abuse_1.png', 'Abuse_2.png', 'Abuse_3.png', 'Abuse_4.png', 'Abuse_5.png', 'Abuse_6.png', 'Abuse_7.png', 'Abuse_8.png', 'Abuse_9.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Emotion: Abuse:   0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/250 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "C:\\dev\\valberts\\Crime-Recognition-from-Context-Representation\\ExpansionNet_v2-master\\video_frames\\train\\Abuse\\Abuse_0.png:   0%|          | 0/250 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "Emotion: Abuse:   0%|          | 0/13 [00:00<?, ?it/s]\n",
      "Split: train:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\dev\\valberts\\Crime-Recognition-from-Context-Representation\\high-level-context-representation\\generate_dataset_annotations.py\", line 303, in <module>\n",
      "    main_caer(root_folder)\n",
      "  File \"C:\\dev\\valberts\\Crime-Recognition-from-Context-Representation\\high-level-context-representation\\generate_dataset_annotations.py\", line 72, in main_caer\n",
      "    raw_caption, nlp_caption = fetch_image_caption(\n",
      "  File \"C:\\dev\\valberts\\Crime-Recognition-from-Context-Representation\\high-level-context-representation\\build_expansionnet_model.py\", line 73, in fetch_image_caption\n",
      "    pil_image = PIL_Image.open(impath)\n",
      "  File \"C:\\Users\\alber\\anaconda3-researchproject\\envs\\pizza\\lib\\site-packages\\PIL\\Image.py\", line 3227, in open\n",
      "    fp = builtins.open(filename, \"rb\")\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\dev\\\\valberts\\\\Crime-Recognition-from-Context-Representation\\\\ExpansionNet_v2-master\\\\video_frames\\\\train\\\\Abuse\\\\Abuse_0.png'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(pizza) C:\\dev\\valberts\\Crime-Recognition-from-Context-Representation\\high-level-context-representation>\n",
      "C:\\dev\\valberts\\Crime-Recognition-from-Context-Representation>"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "%windir%\\System32\\cmd.exe \"/K\" C:\\Users\\alber\\anaconda3-researchproject\\Scripts\\activate.bat\n",
    "conda info --envs\n",
    "conda activate pizza\n",
    "cd high-level-context-representation\n",
    "python generate_dataset_annotations.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3888cb9-e451-4df3-960a-59c6a7d4ac12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7edc90-c3a3-431a-bc32-968dc6706422",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
